{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dftext = pd.read_csv(r\"./alltext.csv\", encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Extract keywords \n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words=stop_words, max_features=100)\n",
    "X = vectorizer.fit_transform(dftext['reviews_lemmatized'])\n",
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "uni_keywords = defaultdict(list)\n",
    "keyword_sentiments = {}\n",
    "\n",
    "# Verify keyword\n",
    "for i in range(len(dftext)):\n",
    "    review = dftext.iloc[i]\n",
    "    university = review['University']\n",
    "    review_text = review['reviews']\n",
    "    review_sentiment = review['sentiment']\n",
    "    review_keywords = [features[index] for index in X[i].indices]\n",
    "\n",
    "    # Use VADER to check emotions\n",
    "    vader_result = sia.polarity_scores(review_text)\n",
    "    vader_sentiment = 'positive' if vader_result['compound'] >= 0.05 else 'negative' if vader_result['compound'] <= -0.05 else 'neutral'\n",
    "\n",
    "    for word in review_keywords:\n",
    "        if word not in keyword_sentiments:\n",
    "            word_sentiment = 'positive' if sia.polarity_scores(word)['compound'] >= 0.05 else 'negative' if sia.polarity_scores(word)['compound'] <= -0.05 else 'neutral'\n",
    "            keyword_sentiments[word] = word_sentiment\n",
    "\n",
    "        if keyword_sentiments[word] == review_sentiment and vader_sentiment == review_sentiment:\n",
    "            uni_keywords[university].append(word)\n",
    "\n",
    "uni_keyword_counts = {uni: Counter(keywords) for uni, keywords in uni_keywords.items()}\n",
    "\n",
    "def extract_keywords(text):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words, max_features=100)\n",
    "    X = vectorizer.fit_transform([text])\n",
    "    features = vectorizer.get_feature_names()\n",
    "    return features\n",
    "\n",
    "def predict_universities(new_review):\n",
    "    # Assuming the comment is what they hope for in their future university\n",
    "    new_review_keywords = extract_keywords(new_review)\n",
    "    new_keywords = [word for word in new_review_keywords if word in keyword_sentiments and keyword_sentiments[word] == 'positive']\n",
    "\n",
    "    uni_scores = defaultdict(int)\n",
    "    for uni, keyword_counts in uni_keyword_counts.items():\n",
    "        for keyword in new_keywords:\n",
    "            uni_scores[uni] += keyword_counts[keyword]\n",
    "\n",
    "    total_count = sum(uni_scores.values())\n",
    "    if total_count == 0:\n",
    "        print(\"No matching universities found.\")\n",
    "        return\n",
    "    uni_probabilities = {uni: (count / total_count) for uni, count in uni_scores.items()}\n",
    "\n",
    "    top_unis = sorted(uni_probabilities, key=uni_probabilities.get, reverse=True)[:5]\n",
    "    s = 0\n",
    "    for uni in top_unis:\n",
    "        s += uni_probabilities[uni]\n",
    "        print(f\"{uni}: {uni_probabilities[uni]:.2%}\")\n",
    "    print(s)\n",
    "    print(uni_probabilities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York University: 13.78%\n",
      "University of California, Santa Barbara: 12.11%\n",
      "University of Texas at Austin: 9.19%\n",
      "University of California, Los Angeles: 7.72%\n",
      "Boston University: 6.26%\n",
      "0.4906054279749478\n",
      "{'Princeton University': 0.014613778705636743, 'Massachusetts Institute of Technology': 0.012526096033402923, 'Harvard University': 0.012526096033402923, 'Stanford University': 0.022964509394572025, 'Yale University': 0.022964509394572025, 'University of Pennsylvania': 0.010438413361169102, 'Duke University': 0.020876826722338204, 'Brown University': 0.027139874739039668, 'Johns Hopkins University': 0.020876826722338204, 'Northwestern University': 0.025052192066805846, 'Columbia University': 0.016701461377870562, 'Cornell University': 0.031315240083507306, 'University of California, Berkeley': 0.04175365344467641, 'University of California, Los Angeles': 0.07724425887265135, 'University of North Carolina at Chapel Hill': 0.033402922755741124, 'Carnegie Mellon University': 0.04175365344467641, 'University of California, San Diego': 0.03966597077244259, 'University of Southern California': 0.05845511482254697, 'University of Texas at Austin': 0.0918580375782881, 'New York University': 0.13778705636743216, 'University of California, Santa Barbara': 0.12108559498956159, 'University of Washington': 0.05636743215031315, 'Boston University': 0.06263048016701461}\n"
     ]
    }
   ],
   "source": [
    "#test model\n",
    "new_review = \"I want to learn at a university that encourages innovation and has a vibrant community life.\"\n",
    "predict_universities(new_review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
